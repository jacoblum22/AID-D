"""
LLM-based narration generator for AID&D prototype.

This module takes structured ToolResult data and generates
immersive, literary narration that goes beyond the deterministic
templates used in tools.
"""

import json
import logging
import os
from typing import Dict, Any, Optional, List
from textwrap import dedent

from openai import OpenAI
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
)

from backend.router.game_state import GameState
from backend.router.validator import ToolResult
from backend.router.visibility import redact_entity, redact_zone
from backend.router.zone_graph import is_zone_discovered
import config


# Set up logging
logger = logging.getLogger(__name__)


class NarrationGenerator:
    """Generates rich narration using 4o-mini from structured tool results."""

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: Optional[str] = None,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
    ):
        """Initialize the narration generator."""
        self.client = OpenAI(
            api_key=api_key or config.OPENAI_API_KEY,
            timeout=30.0,  # Set default timeout for all requests
        )
        self.model = model or config.NARRATION_MODEL
        self.max_tokens = max_tokens or config.NARRATION_MAX_TOKENS
        self.temperature = temperature or config.NARRATION_TEMPERATURE

        # Base system prompt for narration role
        self.system_prompt = dedent(
            """
            You are the Dungeon Master of an AI tabletop RPG.
            Your task is to narrate what happens, given structured data from game mechanics.

            CRITICAL RULES:
            - Write rich, immersive, literary narration with vivid detail
            - Use sensory detail and atmospheric language
            - Stay consistent with the provided facts - do NOT invent new mechanics or outcomes
            - Do NOT reveal hidden or GM-only information
            - Match the tone indicated by tone_tags
            - Focus on the player's perspective and experience
            - Avoid repetitive language and clichÃ©s
            - Make it feel like reading a fantasy novel

            Your narration should feel organic and creative while respecting the mechanical reality.
        """
        ).strip()

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=5),
        retry=retry_if_exception_type(Exception),
    )
    def generate_narration(
        self,
        result: ToolResult,
        world: GameState,
        pov_actor_id: Optional[str] = None,
        previous_narration: str = "",
    ) -> str:
        """
        Generate rich narration from a tool result.

        Args:
            result: The ToolResult from tool execution
            world: Current game state for context
            pov_actor_id: ID of the POV actor (defaults to current_actor)
            previous_narration: Previous narration text for continuity

        Returns:
            Rich narrative text generated by 4o-mini
        """
        try:
            # Determine POV actor
            pov_id = pov_actor_id or world.current_actor
            if not pov_id:
                return result.narration_hint.get("summary", "Something happens.")

            # Get redacted world state for safety - disable cache to avoid stale visibility
            redacted_state = world.get_state(
                pov_id, redact=True, role="player", use_cache=False
            )

            # Build context for the LLM
            context = self._build_context(result, redacted_state, pov_id, world)

            # Create the prompt
            user_prompt = self._create_prompt(result, context, previous_narration)

            # DEBUG: Log the full prompt being sent to GPT-5
            full_input = f"{self.system_prompt}\n\n{user_prompt}"

            # Use INFO level for prompt debugging if explicitly requested, otherwise DEBUG
            prompt_log_level = (
                logging.INFO if os.getenv("SHOW_PROMPTS") else logging.DEBUG
            )
            logger.log(prompt_log_level, f"ðŸŽ­ ===== FULL PROMPT DEBUG =====")
            logger.log(
                prompt_log_level,
                f"ðŸŽ­ SYSTEM PROMPT ({len(self.system_prompt)} chars): {self.system_prompt}",
            )
            logger.log(
                prompt_log_level,
                f"ðŸŽ­ USER PROMPT ({len(user_prompt)} chars): {user_prompt}",
            )
            logger.log(
                prompt_log_level,
                f"ðŸŽ­ FULL INPUT ({len(full_input)} chars): {full_input[:300]}...",
            )
            logger.log(prompt_log_level, f"ðŸŽ­ ===== END PROMPT DEBUG =====")

            # DEBUG: Log which model and settings are being used
            logger.debug(
                f"ðŸŽ­ NARRATION MODEL DEBUG: Using model '{self.model}' with max_tokens={self.max_tokens}"
            )
            logger.debug(
                f"ðŸŽ­ EXACT API MODEL NAME: '{self.model}' (checking for full GPT-5 vs nano)"
            )

            # Call LLM with appropriate API
            if self.model.startswith("gpt-5"):
                logger.debug(f"ðŸš€ Using GPT-5 Responses API with text verbosity=medium")
                # Use Responses API for GPT-5 models with correct verbosity parameter
                response = self.client.responses.create(
                    model=self.model,
                    input=f"{self.system_prompt}\n\n{user_prompt}",
                    text={
                        "verbosity": "medium"
                    },  # Balanced detail without excessive flowery language
                    # Note: timeout is handled at client level, max_output_tokens not supported yet
                )
                narration = response.output_text
                logger.debug(
                    f"ðŸš€ GPT-5 raw response length: {len(narration) if narration else 0}"
                )
                logger.debug(
                    f"ðŸš€ GPT-5 raw response preview: '{narration[:100] if narration else 'EMPTY'}'..."
                )
            else:
                logger.debug(f"âš™ï¸ Using Chat Completions API for non-GPT-5 model")
                # Use Chat Completions API for non-GPT-5 models
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": self.system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    max_completion_tokens=self.max_tokens,
                    temperature=self.temperature,
                    # timeout handled at client level
                )
                narration = response.choices[0].message.content
                logger.debug(
                    f"ðŸŽ­ Chat Completions response length: {len(narration) if narration else 0}"
                )

            logger.debug(
                f"ðŸŽ­ Final narration check: narration={'EXISTS' if narration else 'EMPTY'}"
            )
            if narration and narration.strip():
                return narration.strip()
            else:
                logger.warning(
                    f"ðŸš¨ Narration empty/invalid, falling back to summary: '{result.narration_hint.get('summary', 'Something happens.')}'"
                )
                return result.narration_hint.get("summary", "Something happens.")

        except Exception as e:
            logger.error(f"Narration generation failed: {e}")
            # Fallback to original summary
            return result.narration_hint.get("summary", "Something happens.")

    def _process_zone_entities(
        self, redacted_state: Dict[str, Any], zone_actors: List[str], pov_id: str
    ) -> List[Dict[str, Any]]:
        """Process entities in a zone to extract visible entity information with death status."""
        visible_entities = []

        for actor_id in zone_actors:
            if actor_id != pov_id:  # Don't include self
                # Get entity data from 'entities' field
                actor = redacted_state.get("entities", {}).get(actor_id, {})
                if actor:
                    entity_info = {
                        "id": actor_id,
                        "name": actor.get("name", "unknown entity"),
                        "type": actor.get("type", "unknown"),
                    }

                    # Check if entity is dead (HP = 0) and mark for special narration
                    hp = actor.get("hp", {})
                    current_hp = None
                    if isinstance(hp, dict):
                        current_hp = hp.get("current")

                    # Only check for death if we have valid HP data
                    if current_hp is not None and current_hp <= 0:
                        entity_info["is_dead"] = True
                        entity_info["description"] = (
                            f"the body of {entity_info['name']}"
                        )
                    else:
                        entity_info["is_dead"] = False

                    visible_entities.append(entity_info)

        return visible_entities

    def _build_context(
        self,
        result: ToolResult,
        redacted_state: Dict[str, Any],
        pov_id: str,
        world: GameState,
    ) -> Dict[str, Any]:
        """Build safe context information for the LLM."""

        # Get POV actor info from entities
        pov_actor = redacted_state.get("entities", {}).get(pov_id, {})
        pov_name = pov_actor.get("name", "You")

        # For move actions, we need to describe the DESTINATION zone, not current zone
        # because narration runs before position effects are applied
        if result.tool_id == "move" and result.facts and "to_zone" in result.facts:
            # Use destination zone for movement narration
            target_zone_id = result.facts["to_zone"]
            target_zone = redacted_state.get("zones", {}).get(target_zone_id, {})
            zone_name = target_zone.get("name", "an unknown location")
            zone_description = target_zone.get("description", "")

            # Get visible exits for this zone, excluding the one we just came through
            from_zone_id = result.facts.get("from_zone") if result.facts else None
            visible_exits = []
            zone_exits = target_zone.get("exits", [])
            for exit_info in zone_exits:
                if exit_info.get("blocked", False):
                    continue  # Skip blocked exits
                # Skip the exit that leads back to where we came from
                if from_zone_id and exit_info.get("to") == from_zone_id:
                    continue
                exit_label = exit_info.get("label", "passage")
                exit_direction = exit_info.get("direction", "")
                if exit_direction:
                    visible_exits.append(f"{exit_label} ({exit_direction})")
                else:
                    visible_exits.append(exit_label)

            # Check if this is the first time entering this zone
            is_first_visit = not is_zone_discovered(pov_id, target_zone_id, world)

            # Get actors in the DESTINATION zone (including NPCs the player will encounter)
            zone_actors = target_zone.get("entities", [])
            visible_entities = self._process_zone_entities(
                redacted_state, zone_actors, pov_id
            )

            context_zone_id = target_zone_id
        else:
            # For non-move actions, use current zone
            current_zone_id = pov_actor.get("current_zone")
            current_zone = redacted_state.get("zones", {}).get(current_zone_id, {})
            zone_name = current_zone.get("name", "an unknown location")
            zone_description = current_zone.get("description", "")

            # Get visible exits for this zone
            visible_exits = []
            zone_exits = current_zone.get("exits", [])
            for exit_info in zone_exits:
                if exit_info.get("blocked", False):
                    continue  # Skip blocked exits
                exit_label = exit_info.get("label", "passage")
                exit_direction = exit_info.get("direction", "")
                if exit_direction:
                    visible_exits.append(f"{exit_label} ({exit_direction})")
                else:
                    visible_exits.append(exit_label)

            # For non-move actions, zone is already known (not first visit)
            is_first_visit = False

            # Get visible entities in the current zone
            zone_actors = current_zone.get("entities", [])
            visible_entities = self._process_zone_entities(
                redacted_state, zone_actors, pov_id
            )

            context_zone_id = current_zone_id

        # Get scene atmosphere
        scene = redacted_state.get("scene", {})
        scene_tags = scene.get("tags", {})

        return {
            "pov_actor": {
                "id": pov_id,
                "name": pov_name,
                "hp": pov_actor.get("hp", {}).get("current", "unknown"),
                "max_hp": pov_actor.get("hp", {}).get("max", "unknown"),
            },
            "current_zone": {
                "id": context_zone_id,
                "name": zone_name,
                "description": zone_description,
                "visible_entities": visible_entities,
                "visible_exits": visible_exits,
                "is_first_visit": is_first_visit,  # Add discovery info
            },
            "scene": {
                "round": scene.get("round", 1),
                "tags": scene_tags,
            },
        }

    def _create_prompt(
        self, result: ToolResult, context: Dict[str, Any], previous_narration: str = ""
    ) -> str:
        """Create the prompt for LLM narration generation."""

        # Extract key information first
        tool_id = result.tool_id
        facts = result.facts
        narration_hint = result.narration_hint
        effects = result.effects

        # Process entities to add death status and descriptions for enhanced narration
        enhanced_facts = dict(facts)  # Copy facts to avoid modifying original

        # Add processed entity information if there are visible entities
        processed_entities = []
        for entity in context["current_zone"]["visible_entities"]:
            entity_info = {
                "id": entity["id"],
                "name": entity["name"],
                "type": entity.get("type", "unknown"),
            }

            # Check if entity is dead (HP = 0) for special narration emphasis
            if entity.get("is_dead", False):
                entity_info["status"] = "CORPSE"
                entity_info["description"] = entity.get(
                    "description", f"the body of {entity['name']}"
                )
                entity_info["narration_priority"] = (
                    "HIGH"  # Should be prominently mentioned
                )
            else:
                entity_info["status"] = "alive"

            processed_entities.append(entity_info)

        if processed_entities:
            enhanced_facts["processed_entities"] = processed_entities

        # Use enhanced facts for narration

        # Build effects summary if there are any
        effects_summary = ""
        if effects:
            effects_summary = f"\\nMechanical changes: {len(effects)} effects applied"
            # Add brief summary of major effects
            hp_changes = [e for e in effects if e.get("type") == "hp"]
            if hp_changes:
                effects_summary += f" (including HP changes)"

        # Entity data is now included in the JSON facts, no separate formatting needed

        # Add previous narration for continuity if provided
        previous_context = ""
        if previous_narration.strip():
            previous_context = (
                f"\n[Previous Narration for Context]:\n{previous_narration.strip()}\n"
            )

        # Add discovery context for zone entries
        discovery_context = ""
        if context["current_zone"]["is_first_visit"]:
            discovery_context = f"\n[IMPORTANT: First Time in Zone] - Use discovery language! Instead of naming the location directly, describe what the character discovers (e.g., 'you find yourself in a vast hall' instead of 'you enter the Great Hall')."

        # Streamlined prompt - Enhanced JSON facts contain all necessary data including processed entities
        prompt = dedent(
            f"""
            Generate immersive narration for this game event:
            
            {json.dumps(enhanced_facts, indent=2)}
            {effects_summary}{previous_context}{discovery_context}
            """
        ).strip()

        return prompt


# Global generator instance
_generator_instance: Optional[NarrationGenerator] = None


def initialize_generator(
    api_key: Optional[str] = None, model: Optional[str] = None
) -> None:
    """Initialize the global narration generator."""
    global _generator_instance
    _generator_instance = NarrationGenerator(api_key=api_key, model=model)


def generate_narration(
    result: ToolResult,
    world: GameState,
    pov_actor_id: Optional[str] = None,
    previous_narration: str = "",
) -> str:
    """
    Convenience function to generate narration using the global generator.

    Args:
        result: ToolResult from tool execution
        world: Current game state
        pov_actor_id: Optional POV actor ID

    Returns:
        Rich narrative text
    """
    global _generator_instance
    if _generator_instance is None:
        # Auto-initialize with config defaults
        initialize_generator()

    # Double-check initialization succeeded
    if _generator_instance is None:
        logger.error("Failed to initialize narration generator")
        return result.narration_hint.get("summary", "Something happens.")

    return _generator_instance.generate_narration(
        result, world, pov_actor_id, previous_narration
    )
